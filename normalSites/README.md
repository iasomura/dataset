# Majestic Million URL Validator

This project contains two Python scripts to fetch, validate, and clean URLs from the **Majestic Million** list, which ranks the top million websites on the web.

このプロジェクトには、ウェブ上で最も人気のあるサイトをランキングした**Majestic Million**リストからURLを取得し、検証し、クリーンアップするための2つのPythonスクリプトが含まれています。

## Table of Contents | 目次

- [Overview | 概要](#overview--概要)
- [Features | 特徴](#features--特徴)
- [Requirements | 必要要件](#requirements--必要要件)
- [Installation | インストール](#installation--インストール)
- [Usage | 使用方法](#usage--使用方法)
- [License | ライセンス](#license--ライセンス)

## Overview | 概要

This project automates the process of downloading the top domains from the Majestic Million list, validating the URLs, and cleaning them by removing query parameters. The final result is a list of valid, clean URLs saved to a text file.

このプロジェクトは、Majestic Millionリストからトップドメインをダウンロードし、URLを検証し、クエリパラメータを削除してクリーンアップするプロセスを自動化します。最終結果は、テキストファイルに保存された有効なクリーンなURLリストです。

## Features | 特徴

- Fetches the top 30,000 domains from the Majestic Million list.
- Validates each URL by sending an HTTP request and checking the response status.
- Removes query parameters from valid URLs.
- Saves the cleaned and validated URLs into a file for further use.

- Majestic Millionリストから上位30,000ドメインを取得します。
- HTTPリクエストを送信し、レスポンスのステータスを確認して各URLを検証します。
- 有効なURLからクエリパラメータを削除します。
- クリーンで検証済みのURLをファイルに保存します。

## Requirements | 必要要件

- Python 3.x
- `requests` library
- `concurrent.futures` (for multithreading)

You can install the necessary dependencies by running:

以下のコマンドを実行して、必要な依存関係をインストールできます：

```bash
pip install requests
```

## Installation | インストール

1. Clone this repository to your local machine:

   このリポジトリをローカルマシンにクローンします：

   ```bash
   git clone https://github.com/your-username/majestic-million-url-validator.git
   ```

2. Navigate to the project directory:

   プロジェクトディレクトリに移動します：

   ```bash
   cd majestic-million-url-validator
   ```

3. Install the required dependencies:

   必要な依存関係をインストールします：

   ```bash
   pip install -r requirements.txt
   ```

## Usage | 使用方法

The project consists of two scripts:

このプロジェクトには、2つのスクリプトが含まれています。

### 1. Fetch and Validate Top Domains (`get_normalSites.py`)

This script fetches the top domains from the Majestic Million list, validates the URLs, and saves the results to a CSV file (`top_sites.csv`).

このスクリプトは、Majestic Millionリストからトップドメインを取得し、URLを検証し、結果をCSVファイル(`top_sites.csv`)に保存します。

Run the script:

スクリプトを実行します：

```bash
python get_normalSites.py
```

This will:
- Download the Majestic Million CSV file.
- Validate the URLs (check their status, redirects, etc.).
- Save the results into `top_sites.csv`.

これにより：
- Majestic MillionのCSVファイルがダウンロードされます。
- URLを検証します（ステータスやリダイレクトをチェック）。
- 結果を`top_sites.csv`に保存します。

### 2. Clean and Save Valid URLs (`ValidUrlSaver.py`)

This script reads the CSV file generated by the first script, removes any query parameters from the URLs, checks for valid HTTP responses, and saves the clean URLs to a text file (`normalSite.txt`).

このスクリプトは、最初のスクリプトで生成されたCSVファイルを読み込み、URLからクエリパラメータを削除し、有効なHTTPレスポンスをチェックし、クリーンなURLをテキストファイル(`normalSite.txt`)に保存します。

Run the script:

スクリプトを実行します：

```bash
python ValidUrlSaver.py
```

This will:
- Read the `top_sites.csv` file.
- Remove query parameters from each URL.
- Check for valid HTTP responses.
- Save valid, cleaned URLs to `normalSite.txt`.

これにより：
- `top_sites.csv`ファイルが読み込まれます。
- 各URLからクエリパラメータを削除します。
- 有効なHTTPレスポンスを確認します。
- 有効なクリーンなURLが`normalSite.txt`に保存されます。

### Sample Output | サンプル出力

The final output will be saved in:
- `top_sites.csv`: Contains all domains with their validation results.
- `normalSite.txt`: Contains only the valid URLs without query parameters.

最終出力は以下のファイルに保存されます：
- `top_sites.csv`: すべてのドメインとその検証結果が含まれています。
- `normalSite.txt`: クエリパラメータなしの有効なURLのみが含まれています。

